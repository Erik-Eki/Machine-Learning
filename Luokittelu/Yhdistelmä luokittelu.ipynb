{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pml_utils import get_mnist, show_failures\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded: train: 1347 test: 450\n",
      "X_train: (1347, 64)\n",
      "y_train: (1347,)\n",
      "X_test (450, 64)\n",
      "y_test (450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)\n",
    "\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for outliers, which isn't really needed with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-202.38404850036397"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = X_train.mean() - (3*X_train.std())\n",
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.02089140002386"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val = X_train.mean() + (3*X_train.std())\n",
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = X_train[X_train > max_val]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outliers\n",
    "\n",
    "### Standardazion, which again, won't be needed with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_standardized = (X_train - X_train.min())/X_train.std()\n",
    "x_standardized[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4240738943915651\n",
      "Standard Deviation: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \" + str(x_standardized.mean()))\n",
    "print(\"Standard Deviation: \" + str(x_standardized.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Voting\n",
    "\n",
    "Voting ensamble combines the prediction from several machine learning models together.\n",
    "\n",
    "It's like creating the ultimate Frankenstein-machine-learning model.\n",
    "\n",
    "#### In the case of classification,\n",
    "the predictions for each label are summed and the label with the majority vote is predicted.\n",
    "\n",
    "#### There are 2 types of voting methods: Hard and soft:\n",
    "\n",
    "- Hard voting\n",
    "    - Summing the predictions for each class label and predicting the class label with the most votes. \n",
    "- Soft voting\n",
    "    - Summing the predicted probabilities (or probability-like scores) for each class label and predicting the class label with the largest probability.\n",
    "\n",
    "Voting ensamble is a meta-model, so it can be used with any collection of existing trained models.\n",
    "\n",
    "A voting ensemble is appropriate when you have two or more models that perform well on a predictive modeling task. The models used in the ensemble must mostly agree with their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf1 = KNeighborsClassifier()\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=50,\n",
    "                              random_state=1)\n",
    "\n",
    "clf3 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=5,\n",
       "                                                   p=2, weights='uniform')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=50,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=1, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('gnb',\n",
       "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_vote = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "                         voting='hard')\n",
    "\n",
    "clf_vote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 450 digits with accuracy: 0.9755555555555555\n"
     ]
    }
   ],
   "source": [
    "#eclf1.predict(X_test)\n",
    "pred_vote = clf_vote.predict(X_test)\n",
    "print('Predicted', len(pred_vote), 'digits with accuracy:', accuracy_score(y_test, pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='multinomial',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='lbfgs',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     ccp_alpha=0.0,\n",
      "                                                     class_weight=Non...\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     max_samples=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=50,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=1, verbose=0,\n",
      "                                                     warm_start=False)),\n",
      "                             ('gnb',\n",
      "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "Predicted 450 digits with accuracy: 0.9577777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf1 = LogisticRegression(multi_class='multinomial',\n",
    "                             random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1),\n",
    "                                     ('rf', clf2),\n",
    "                                     ('gnb', clf3)],\n",
    "                         voting='hard')\n",
    "\n",
    "print(eclf1.fit(X_train, y_train))\n",
    "pred_bnb = eclf1.predict(X_test)\n",
    "print('Predicted', len(pred_bnb), 'digits with accuracy:', accuracy_score(y_test, pred_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(eclf1.named_estimators_.lr.predict(X_train),\n",
    "               eclf1.named_estimators_['lr'].predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 2 6 6 7 1 9 8 5 2 8 6 6 6 6 1 0 5 8 8 7 8 4 7 5 4 9 2 9 4 7 6 8 9 4 3\n",
      " 1 0 1 8 6 7 7 1 0 7 6 2 1 9 6 7 9 0 0 5 1 6 3 0 2 3 4 1 9 2 6 9 1 8 3 5 1\n",
      " 2 1 2 2 9 7 2 3 6 0 5 3 7 5 1 2 9 9 3 1 7 7 4 8 5 8 5 5 2 5 9 0 7 1 4 7 3\n",
      " 4 8 9 7 9 8 2 1 5 2 5 5 4 1 7 0 6 1 5 5 9 9 5 9 9 5 7 5 6 2 8 6 9 6 1 5 1\n",
      " 5 9 9 1 5 3 6 1 8 9 7 7 6 7 6 5 6 0 8 8 9 8 6 1 0 4 1 6 3 8 6 7 4 9 6 3 0\n",
      " 3 3 3 0 7 7 5 7 8 0 7 1 9 6 4 5 0 1 4 6 4 3 3 0 9 5 3 2 1 4 2 1 6 8 9 2 4\n",
      " 9 3 7 6 2 3 3 1 6 9 3 6 3 1 2 0 7 6 1 1 9 7 2 7 1 5 5 7 5 3 3 7 2 7 5 5 7\n",
      " 0 9 1 6 5 9 7 4 3 8 0 3 6 4 6 3 1 6 8 8 8 4 6 7 5 2 4 5 3 2 4 6 9 4 5 4 3\n",
      " 4 6 2 9 0 1 7 2 0 9 6 0 4 2 0 7 9 8 5 7 8 2 8 4 3 7 2 6 9 1 5 1 0 8 2 8 9\n",
      " 5 6 8 2 7 2 1 5 1 6 4 5 0 9 4 1 1 7 0 8 9 0 5 4 3 8 8 6 5 3 4 4 4 8 8 7 0\n",
      " 9 6 3 5 2 3 0 8 8 3 1 3 3 0 0 4 6 0 7 7 6 2 0 4 4 2 3 7 1 9 8 6 8 5 6 2 2\n",
      " 3 1 7 7 8 0 3 3 2 1 5 5 9 1 3 7 0 0 4 0 4 5 9 3 3 4 3 1 8 9 8 3 6 8 1 6 2\n",
      " 1 7 5 5 1 9]\n"
     ]
    }
   ],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "                         voting='soft')\n",
    "\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "print(eclf2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 30)\n"
     ]
    }
   ],
   "source": [
    "print(eclf2.transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stacking\n",
    "\n",
    "Stacking model combines the predictions from multiple models on the same dataset, like bagging and boosting.\n",
    "\n",
    "Stacking is about finding the most appropiate machine learning model to use from a group of many competent ones.\n",
    "\n",
    "- Unlike bagging, in stacking, the models are typically different (e.g. not all decision trees) and fit on the same dataset (e.g. instead of samples of the training dataset).\n",
    "- Unlike boosting, in stacking, a single model is used to learn how to best combine the predictions from the contributing models (e.g. instead of a sequence of models that correct the predictions of prior models).\n",
    "\n",
    "#### The architecture of a stacking mode:\n",
    "\n",
    "- Level-0 Models (Base-Models)\n",
    "    - Models fit on the training data and whose predictions are compiled.\n",
    "- Level-1 Model (Meta-Model)\n",
    "    - Model that learns how to best combine the predictions of the base models.\n",
    "    \n",
    "The meta-model is trained on the predictions made by base models on out-of-sample data. \n",
    "\n",
    "That is, data not used to train the base models is fed to the base models, predictions are made, and these predictions, along with the expected outputs, provide the input and output pairs of the training dataset used to fit the meta-model.\n",
    "\n",
    "The outputs from the base models used as input to the meta-model may be real value in the case of regression, and probability values, probability like values, or class labels in the case of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9622222222222222"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "              ('svr', make_pipeline(StandardScaler(),\n",
    "                                    LinearSVC(random_state=42)))]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking model returns with the accuracy of 96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagging (Bootstrap Aggregation)\n",
    "\n",
    "Specifically, it is an ensemble of decision tree models, although the bagging technique can also be used to combine the predictions of other types of models.\n",
    "\n",
    "It's based on the *\"bootstrap\"* sample:\n",
    "\n",
    "A *bootstrap sample* is a sample of a dataset with **replacement**. **Replacement** means that a sample drawn from the dataset is replaced, allowing it to be **selected again** and perhaps multiple times in the new sample. This means that the sample may have **duplicate examples** from the original dataset.\n",
    "\n",
    "The bootstrap sampling technique is used to estimate a population statistic from a small data sample. This is achieved by drawing multiple bootstrap samples, calculating the statistic on each, and reporting the mean statistic across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BaggingClassifier()\n",
    "\n",
    "# Evaluate the model using **repeated stratified k-fold cross-validation**, with three repeats and 10 folds. \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922 (0.020)\n"
     ]
    }
   ],
   "source": [
    "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy of the model across all repeats and folds.\n",
    "print('Accuracy: %.3f (%.3f)' % (n_scores.mean(), n_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is about 92% on default hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the amount of n_features to create a list for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# list of random in between a range 0 to 10\n",
    "randomIntList = []\n",
    "\n",
    "for i in range(0, 64):\n",
    "    x = random.randint(0, 10)\n",
    "    randomIntList.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9985152190051967\n",
      "\n",
      "Train accuracy: 0.9155555555555556\n",
      "Predicted Class:  4\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"\\nTrain accuracy:\", model.score(X_test, y_test))\n",
    "# make a single prediction\n",
    "# Prediction requires a 1D or 2D array\n",
    "yhat = model.predict([randomIntList])\n",
    "\n",
    "print('Predicted Class: ', yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.940 (0.005)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d391dc12f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# store the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-d391dc12f92d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# evaluate the model and collect the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [10, 50, 100, 500, 500, 1000, 5000]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train, y_train)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Boosting\n",
    "\n",
    "Boosting creates a strong classifier from multiple weak ones.\n",
    "\n",
    "Model is built from the training data, then a second model is created which corrects the first one's errors. \n",
    "\n",
    "Models are added until the training set is predicted perfectly or a maximum number of models are added.\n",
    "\n",
    "**AdaBoost** was the first really successful boosting algorithm developed for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200,\n",
    "                         random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict([randomIntList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8864142538975501"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# General-use classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\tmodels.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "\tmodels.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "\tmodels.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "\tmodels.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "\tmodels.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models_voting():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn1'] = KNeighborsClassifier(n_neighbors=1)\n",
    "\tmodels['knn3'] = KNeighborsClassifier(n_neighbors=3)\n",
    "\tmodels['knn5'] = KNeighborsClassifier(n_neighbors=5)\n",
    "\tmodels['knn7'] = KNeighborsClassifier(n_neighbors=7)\n",
    "\tmodels['knn9'] = KNeighborsClassifier(n_neighbors=9)\n",
    "\tmodels['hard_voting'] = get_voting()\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression()))\n",
    "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
    "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
    "\tlevel0.append(('svm', SVC()))\n",
    "\tlevel0.append(('bayes', GaussianNB()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models_stacking():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of model performance\n",
    "\n",
    "Boxplot to show the distribution of model error scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn1 0.988 (0.009)\n",
      ">knn3 0.988 (0.009)\n",
      ">knn5 0.988 (0.009)\n",
      ">knn7 0.984 (0.011)\n",
      ">knn9 0.980 (0.009)\n",
      ">hard_voting 0.987 (0.009)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models_voting()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X_train, y_train)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.title(\"Voting performances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.966 (0.012)\n",
      ">knn 0.988 (0.009)\n",
      ">cart 0.844 (0.033)\n",
      ">svm 0.987 (0.006)\n",
      ">bayes 0.834 (0.021)\n",
      ">stacking 0.987 (0.007)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models_stacking()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X_train, y_train)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.title(\"Voting performances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cart and bayes models seem to have the worst mean and median scores.\n",
    "\n",
    "The other ones are fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.85610953,  1.62260165, ...,  0.89887909,\n",
       "         1.74648816,  0.38393236],\n",
       "       [ 0.        , -0.33833791, -0.88123922, ...,  1.06879069,\n",
       "        -0.25013357, -0.18751172],\n",
       "       [ 0.        , -0.33833791, -0.255279  , ...,  0.38914426,\n",
       "        -0.49971129, -0.18751172],\n",
       "       ...,\n",
       "       [ 0.        , -0.33833791, -0.04662559, ..., -1.14006023,\n",
       "        -0.49971129, -0.18751172],\n",
       "       [ 0.        , -0.33833791, -0.255279  , ..., -1.14006023,\n",
       "        -0.49971129, -0.18751172],\n",
       "       [ 0.        , -0.33833791,  0.16202781, ...,  0.72896748,\n",
       "        -0.49971129, -0.18751172]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 9, ..., 7, 7, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y2 = label_encoder.fit_transform(y_train)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newData = [[0,51]]\n",
    "#print(algorithm.predict(newData))\n",
    "'''plot_colors = \"br\"\n",
    "plot_step = 0.02\n",
    "class_names = \"AB\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plt.subplot(121)\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "Z = bdt.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# Plot the training points\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X_train[idx, 0], X_train[idx, 1],\n",
    "                c=c, cmap=plt.cm.Paired,\n",
    "                s=20, edgecolor='k',\n",
    "                label=\"Class %s\" % n)\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Decision Boundary')\n",
    "\n",
    "# Plot the two-class decision scores\n",
    "twoclass_output = bdt.decision_function(X_train)\n",
    "plot_range = (twoclass_output.min(), twoclass_output.max())\n",
    "plt.subplot(122)\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    plt.hist(twoclass_output[y == i],\n",
    "             bins=10,\n",
    "             range=plot_range,\n",
    "             facecolor=c,\n",
    "             label='Class %s' % n,\n",
    "             alpha=.5,\n",
    "             edgecolor='k')\n",
    "X_train, y_train = plt.axis()\n",
    "plt.axis((X_train, y_train * 1.2))\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Samples')\n",
    "plt.xlabel('Score')\n",
    "plt.title('Decision Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.35)\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
