{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with an ensemble of classifiers \n",
    "\n",
    "In this notebook, we'll use a [classifier emsemble](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier) to classify MNIST digits using scikit-learn (version 0.20 or later required).\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pml_utils import get_mnist, show_failures\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import __version__\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "assert(LV(__version__) >= LV(\"0.20\")), \"Version >= 0.20 of sklearn is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST data. First time we need to download the data, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not downloading, file already exists: MNIST/train-images-idx3-ubyte\n",
      "Not downloading, file already exists: MNIST/train-labels-idx1-ubyte\n",
      "Not downloading, file already exists: MNIST/t10k-images-idx3-ubyte\n",
      "Not downloading, file already exists: MNIST/t10k-labels-idx1-ubyte\n",
      "MNIST data loaded: train: 60000 test: 10000\n",
      "X_train: (60000, 784)\n",
      "y_train: (60000,)\n",
      "X_test (10000, 784)\n",
      "y_test (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_mnist('MNIST')\n",
    "\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data (`X_train`) is a matrix of size (60000, 784), i.e. it consists of 60000 digits expressed as 784 sized vectors (28x28 images flattened to 1D). `y_train` is a 60000-dimensional vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual classifiers\n",
    "\n",
    "Let's first define and train a set of different classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Predicted 10000 digits with accuracy: 0.8891\n",
      "CPU times: user 3min 9s, sys: 32.8 ms, total: 3min 9s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_sgd = SGDClassifier()\n",
    "print(clf_sgd.fit(X_train, y_train))\n",
    "pred_sgd = clf_sgd.predict(X_test)\n",
    "print('Predicted', len(pred_sgd), 'digits with accuracy:', accuracy_score(y_test, pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Predicted 10000 digits with accuracy: 0.8769\n",
      "CPU times: user 28.8 s, sys: 132 ms, total: 28.9 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "print(clf_dt.fit(X_train, y_train))\n",
    "pred_dt = clf_dt.predict(X_test)\n",
    "print('Predicted', len(pred_dt), 'digits with accuracy:', accuracy_score(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=128.0, class_prior=None, fit_prior=True)\n",
      "Predicted 10000 digits with accuracy: 0.8433\n",
      "CPU times: user 1.33 s, sys: 244 ms, total: 1.57 s\n",
      "Wall time: 659 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_bnb = BernoulliNB(binarize=128.)\n",
    "print(clf_bnb.fit(X_train, y_train))\n",
    "pred_bnb = clf_bnb.predict(X_test)\n",
    "print('Predicted', len(pred_bnb), 'digits with accuracy:', accuracy_score(y_test, pred_bnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble classifier\n",
    "\n",
    "The goal of ensemble methods is to combine the predictions of several base classifiers to improve generalizability and robustness.\n",
    "\n",
    "### Learning\n",
    "\n",
    "We use [`VotingClassifier`](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier) to combine the results of the individual classifiers.\n",
    "The default mode is to use majority (`\"hard\"`) voting, where each classifier gets a vote and the final prediction is the class that gets the majority of the votes.\n",
    "Another option is to use the average of the predicted probabilities (`\"soft\"` voting), which however requires that all used individual classifiers are able to predict class probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 228 ms, total: 3min 56s\n",
      "Wall time: 3min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight=None,\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=...\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort='deprecated',\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best')),\n",
       "                             ('bnb',\n",
       "                              BernoulliNB(alpha=1.0, binarize=128.0,\n",
       "                                          class_prior=None, fit_prior=True))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_vote = VotingClassifier(estimators=[('sgd', clf_sgd),\n",
    "                                        ('dt', clf_dt),\n",
    "                                        ('bnb', clf_bnb)],\n",
    "                            voting='hard')\n",
    "clf_vote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "The classification accuracy of the ensemble classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 10000 digits with accuracy: 0.9055\n"
     ]
    }
   ],
   "source": [
    "pred_vote = clf_vote.predict(X_test)\n",
    "print('Predicted', len(pred_vote), 'digits with accuracy:', accuracy_score(y_test, pred_vote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "We can compute the confusion matrix to see which digits get mixed the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows: true classes; columns: predicted classes):\n",
      "\n",
      "[[ 968    0    0    0    0    3    4    1    4    0]\n",
      " [   0 1124    3    0    0    2    4    0    2    0]\n",
      " [  13   13  921   10   11    1   10   11   41    1]\n",
      " [   9    6   35  873    2   31    4   10   28   12]\n",
      " [   3    7    8    1  901    1    9    0    7   45]\n",
      " [  16   11    8   46   20  752   13    3   13   10]\n",
      " [  19    7   12    1    7   15  887    0   10    0]\n",
      " [   2   23   22    7   14    0    1  919    5   35]\n",
      " [  13   20   12   28   14   19    6    9  838   15]\n",
      " [  20   14    5   10   52    6    1   14   15  872]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels=[str(i) for i in range(10)]\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "cm=confusion_matrix(y_test, pred_vote, labels=labels)\n",
    "print(cm); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, precision and recall\n",
    "\n",
    "Classification accuracy for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_vote, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Failure analysis\n",
    "\n",
    "We can also do some failure analysis.  Let's check the 10 first wrongly predicted digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_failures(pred_vote, y_test, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "Try adding various classifiers covered on this course to the ensemble and experiment with different setups.  \n",
    "\n",
    "Report the highest classification accuracy you manage to obtain.  Also mark down the parameters you used, so others can try to reproduce your results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
